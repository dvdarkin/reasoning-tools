# Quality Criteria for Reasoning Tool Extractions

## Automated Structural Checks

- [ ] File has all required sections (meta-framing, tiers, quick reference, usage notes)
- [ ] 10-15 tools total
- [ ] 3-4 tier structure
- [ ] Each tool: 400-600 words
- [ ] Each tool has all 7 components (What, Why, Key Move, Classic, Surprising, Failure, Go Deeper)
- [ ] At least 1-2 citations per tool

## Content Quality Checks

### Mental Operations (CRITICAL)
- [ ] Each "key move" describes an OPERATION, not a concept
- [ ] Good: "For any choice, identify the realistic next-best use of the same resources"
- [ ] Bad: "Understand opportunity cost"

### Transfer Evidence
- [ ] Each "surprising application" is from a genuinely different domain
- [ ] Not just different examples from the same domain
- [ ] Demonstrates the tool's portability

### Failure Modes
- [ ] Specific scenarios where the tool misleads
- [ ] Shows understanding of boundaries
- [ ] Not generic ("can be misused")

### Citations
- [ ] Academic sources, textbooks, primary literature
- [ ] Not pop science, blogs, or uncited claims
- [ ] Author and title provided

## Red Flags (REJECT if present)

- ❌ Domain-specific facts masquerading as tools
- ❌ "Common sense" that everyone already knows
- ❌ Unfalsifiable interpretive frameworks
- ❌ Pure theory without practical operation
- ❌ No evidence of transfer to other domains
- ❌ Vague failure modes
- ❌ Missing or poor citations

## Acceptance Criteria

To accept an extraction:
- All automated checks pass
- At least 80% of tools pass content quality checks
- No critical red flags present
- "Surprising applications" genuinely demonstrate transfer
